# Phase 2 - Week 3 - Day 3-4: PostgreSQL & Redis Setup

## ğŸ¯ Goal: Add database layer for persistence and caching

**Time Budget: 2-3 hours total**

---

## ğŸ“‹ What You're Adding

### **PostgreSQL**
- Relational database for historical price data
- Time-series optimized tables
- Proper schema design with indexes
- Views for common queries

### **Redis**
- In-memory cache for latest prices
- Fast reads for API endpoints
- Pub/Sub for real-time updates (future)

### **pgAdmin** (Bonus)
- Web-based GUI for PostgreSQL
- Makes debugging and exploration easier
- Professional database management tool

---

## ğŸš€ Step 1: Update Docker Compose (Already Done!)

Your docker-compose.yml now includes:
- âœ… PostgreSQL with TimescaleDB (port 5433)
- âœ… Redis (port 6379)
- âœ… pgAdmin (port 5050)
- âœ… Health checks for all services
- âœ… Persistent volumes for data

---

## ğŸ”§ Step 2: Start the New Services

```bash
cd C:\Real-Time-Cryptocurrency-Market-Analyzer

# Stop existing services
docker-compose down

# Start everything (including new services)
docker-compose up -d

# Wait 30 seconds for initialization
timeout /t 30

# Check status
docker-compose ps
```

**Expected Output:**
```
NAME        STATUS
kafka       Up
kafka-ui    Up
zookeeper   Up
postgres    Up (healthy) - TimescaleDB enabled
redis       Up (healthy)
pgadmin     Up
```

---

## ğŸ—ƒï¸ Step 3: Verify PostgreSQL

### **Check Database Initialization**

```bash
# Check PostgreSQL logs
docker-compose logs postgres

# You should see:
# "Database schema initialized successfully!"
# "Tables created: cryptocurrencies, raw_price_data..."
```

### **Connect to PostgreSQL**

**Option 1: Using Docker (Quick Test)**
```bash
# Connect to PostgreSQL container
docker exec -it postgres psql -U crypto_user -d crypto_db

# Once inside, run:
\dt              # List all tables
\d cryptocurrencies  # Describe cryptocurrencies table
SELECT * FROM cryptocurrencies;  # View initial data

# Exit
\q
```

**Option 2: Using pgAdmin (GUI)**
1. Open browser: **http://localhost:5050**
2. Login:
   - Email: `admin@crypto.com`
   - Password: `admin`
3. Add Server:
   - Right-click "Servers" â†’ Register â†’ Server
   - **General Tab:**
     - Name: `Crypto DB`
   - **Connection Tab:**
     - Host: `postgres` (container name)
     - Port: `5432`
     - Database: `crypto_db`
     - Username: `crypto_user`
     - Password: `crypto_pass`
4. Click **Save**
5. Explore:
   - Servers â†’ Crypto DB â†’ Databases â†’ crypto_db â†’ Schemas â†’ public â†’ Tables

---

## ğŸ”´ Step 4: Verify Redis

### **Test Redis Connection**

```bash
# Connect to Redis container
docker exec -it redis redis-cli

# Once inside, run:
PING               # Should return: PONG
SET test "Hello"   # Should return: OK
GET test           # Should return: "Hello"
DEL test           # Clean up test key

# Exit
exit
```

### **Test Redis Persistence**

```bash
# Set a value
docker exec -it redis redis-cli SET mykey "persistent_value"

# Restart Redis
docker-compose restart redis

# Check if value persists (should still be there)
docker exec -it redis redis-cli GET mykey
```

---

## ğŸ“Š Step 5: Explore Database Schema

### **Tables Created**

1. **`cryptocurrencies`**
   - Master table for supported coins
   - Pre-populated with BTC and ETH
   - Stores: symbol, name, coingecko_id

2. **`raw_price_data`**
   - High-frequency price updates from Kafka
   - Stores: price, volume, market_cap, timestamp
   - Indexed for fast time-based queries

3. **`price_aggregates_1m`**
   - Pre-computed 1-minute OHLC (Open, High, Low, Close)
   - Generated by Flink (in Week 5-7)
   - Stores: open, high, low, close, avg, volume

4. **`price_alerts`**
   - User-defined price alerts (future feature)
   - Triggers when price crosses threshold

5. **`processing_metadata`**
   - Tracks Kafka consumer offsets
   - Enables exactly-once processing semantics

### **Views Created**

1. **`v_latest_prices`**
   - Shows latest price for each cryptocurrency
   - Quick lookup for API endpoints

2. **`v_price_stats_24h`**
   - 24-hour statistics: min, max, avg, median
   - Useful for dashboards

---

## ğŸ§ª Step 6: Test Database Queries

**In pgAdmin Query Tool or psql:**

```sql
-- 1. Check cryptocurrencies
SELECT * FROM cryptocurrencies;

-- Expected output:
-- id | symbol | name      | coingecko_id | is_active | created_at
-- 1  | BTC    | Bitcoin   | bitcoin      | true      | ...
-- 2  | ETH    | Ethereum  | ethereum     | true      | ...

-- 2. Check table structure
\d raw_price_data

-- 3. Verify indexes exist
SELECT tablename, indexname 
FROM pg_indexes 
WHERE schemaname = 'public' 
ORDER BY tablename, indexname;

-- 4. Check views
SELECT * FROM v_latest_prices;
-- (Will be empty until we start producing data in Week 4)
```

---

## ğŸ“ Understanding the Schema Design

### **Why Time-Series Optimization?**

Cryptocurrency data is **time-series** - values changing over time:
- Need fast INSERT (thousands per second)
- Need fast range queries (last 1 hour, last 24 hours)
- Need aggregations (avg price in 1-minute windows)

**Optimizations applied:**
- Indexes on `(crypto_id, timestamp DESC)`
- Separate aggregation tables to avoid scanning raw data
- Views for common queries
- TimescaleDB support (optional, for production)

### **Why Two Price Tables?**

1. **`raw_price_data`** - Every single price update
   - High frequency (~1-10 per second per coin)
   - Kept for 7 days (configurable)
   - Used for: Real-time displays, replay, debugging

2. **`price_aggregates_1m`** - Pre-computed summaries
   - Low frequency (1 per minute per coin)
   - Kept indefinitely
   - Used for: Charts, historical analysis, trends

**Interview talking point:**
> "I implemented a two-tier storage strategy: raw data for real-time needs with 7-day retention, and pre-aggregated data for long-term analysis. This reduces storage costs while maintaining query performance."

---

## ğŸ“¸ Portfolio Screenshots

Capture these:
1. `docker-compose ps` showing all 6 services running
2. pgAdmin dashboard showing the database tables
3. psql output of `SELECT * FROM cryptocurrencies;`
4. Redis CLI showing `PING` â†’ `PONG`

---

## âœ… Success Criteria

- [ ] PostgreSQL container running and healthy
- [ ] Redis container running and healthy
- [ ] pgAdmin accessible at localhost:5050
- [ ] Can connect to PostgreSQL via pgAdmin
- [ ] Database schema initialized (5 tables, 2 views)
- [ ] Initial cryptocurrencies inserted (BTC, ETH)
- [ ] Redis responds to PING
- [ ] All indexes created successfully

---

## ğŸ› Troubleshooting

### **Problem: PostgreSQL container won't start**

```bash
# Check logs
docker-compose logs postgres

# Common issues:
# - Port 5432 already in use (stop other PostgreSQL)
# - init-db.sql syntax error (check logs for line number)
```

### **Problem: Can't connect from pgAdmin**

- Make sure host is `postgres` (not `localhost`)
- Use container name for internal Docker networking
- Check postgres container is healthy: `docker-compose ps`

### **Problem: Redis connection refused**

```bash
# Restart Redis
docker-compose restart redis

# Check if it's running
docker-compose ps redis

# Check logs
docker-compose logs redis
```

### **Problem: init-db.sql didn't run**

```bash
# PostgreSQL only runs init scripts on FIRST startup
# If tables not created, delete volume and restart:

docker-compose down -v  # WARNING: Deletes all data
docker-compose up -d
```

---

## ğŸ“ Interview Talking Points

**Q: Why PostgreSQL for cryptocurrency data?**
> "PostgreSQL offers strong ACID guarantees, excellent time-series query performance with proper indexing, and support for extensions like TimescaleDB for production optimization. The JSON support also lets us store flexible metadata."

**Q: Why Redis as a cache?**
> "Redis provides sub-millisecond latency for reads, perfect for API endpoints that need latest prices. Its in-memory nature allows thousands of concurrent reads. I configured append-only file (AOF) persistence to prevent data loss on restart."

**Q: How did you design the schema?**
> "I followed time-series best practices: separate raw and aggregated tables, proper indexing on timestamp + crypto_id, views for common queries, and metadata tables for exactly-once processing. The schema supports horizontal scaling via partitioning if needed."

---

## â­ï¸ Next Steps (Day 5-7)

After verifying PostgreSQL and Redis:
1. Add Flink to docker-compose.yml
2. Configure JobManager and TaskManager
3. Access Flink Web UI
4. Submit a test Flink job

---

## ğŸ’¾ Commit Your Work

```bash
# Stage changes
git add docker-compose.yml configs/init-db.sql PHASE2_DAY3-4.md

# Commit
git commit -m "feat(postgres): add PostgreSQL and Redis to infrastructure

- Added PostgreSQL 15 with custom schema (5 tables, 2 views)
- Added Redis with AOF persistence enabled
- Added pgAdmin for database management
- Designed time-series optimized schema for crypto price data
- Created indexes for efficient timestamp-based queries
- Added health checks for all database services

Completes Phase 2, Week 3, Day 3-4 objectives"

# Push
git push origin feature/docker-setup
```

---

**Time to get your database layer running, bhau!** ğŸ’ª

Run `docker-compose down && docker-compose up -d` and let me know once you see all 6 containers up! ğŸš€
